# AI Workflow Design

スキルやマルチステップのAIワークフロー設計における、コンテキスト管理・データフロー・ライフサイクルの指針。

## コンテキストのJust-in-Time戦略

- **scope**: RAG、ツール出力、メモリ等の動的コンテキスト管理
- **action**: 全データを事前ロードせず、基本コンテキストのみ事前取得し、追加探索は必要時に実行するハイブリッドアプローチを採用する。
- **rationale**: 全データの事前ロードは無関係な情報でコンテキストを汚染し精度を低下させる。必要時の動的ロードでコンテキストを効率的に管理できる。
- **source**: docs/knowledge/context-design.md

## マルチフェーズワークフローのリセットポイント設計

- **scope**: 複数ターンで情報を蓄積するタスク
- **action**: 蓄積された決定事項を統合し、新鮮な単一プロンプトとして新しいインスタンスに送信する「リセットポイント」を設計する。
- **rationale**: 200,000+のシミュレーション会話で、シングルターンからマルチターンへの移行で平均39%の性能低下が確認された。Concat-and-Retry手法で精度が90%超に回復し、シングルターン性能にほぼ一致する。Claude Codeのauto-compactionはこの形式化に相当する。
- **source**: docs/knowledge/context-design.md

## 2回失敗後の新規セッション切り替え

- **scope**: 同一セッション内で修正を繰り返す場合
- **action**: 2回の修正失敗後は、セッションを新規にして書き直す。
- **rationale**: マルチターン劣化の「回答アンカリング」により、過去の誤った回答に依存し肥大化した回答が生成される。新規セッションで書き直す方が効率的。
- **source**: docs/knowledge/context-design.md

## ツール出力の選択的保持

- **scope**: ファイル内容、検索結果、API応答等の大きなツール出力
- **action**: ツール出力の全体をコンテキストに入れるのではなく、関連部分のみを選択的に保持する（観察マスキング）。
- **rationale**: Riceプラットフォームで長期記憶+短期状態管理の統合によりコンテキスト消費60%削減を達成。不要部分を除去することで完全な情報を保持しつつ不要なトークン消費を防ぐ。Cursor, Warpが採用するより洗練されたアプローチ。
- **conditions**: 要約アプローチは実装が簡単だが、詳細が失われるリスクがある。詳細が重要なタスクでは観察マスキングを優先すべき。
- **source**: docs/knowledge/context-design.md

## コンテキスト更新のインクリメンタル方式

- **scope**: セッション間で蓄積される知識・教訓の管理
- **action**: 全面書き換えではなく、構造化デルタ更新、決定論的マージ、重複排除、プルーニングによるインクリメンタル更新を採用する（grow-and-refine原則）。
- **rationale**: ACEフレームワークの定量結果でエージェントタスク+10.6%、金融タスク+8.6%、適応レイテンシ82-92%削減、トークンコスト75-84%削減を達成。「簡潔化バイアス」（ドメイン洞察を要約のために削除）と「コンテキスト崩壊」（反復的書き換えで詳細が劣化）を防止する。
- **source**: docs/knowledge/context-design.md

## プロンプトキャッシュを意識した設計

- **scope**: 同一プレフィックスを持つリクエストが複数存在するワークフロー
- **action**: プロンプトキャッシュを有効化する。共通プレフィックス（システムプロンプト、テンプレート等）をリクエスト間で揃え、キャッシュヒット率を高める設計にする。
- **rationale**: LLMクエリの31%がセマンティックに類似。Anthropicではキャッシュ読み取りが基本入力料金の0.1倍（90%割引）で、最大85%のレイテンシ削減も達成。
- **source**: docs/knowledge/llmops-optimization.md

