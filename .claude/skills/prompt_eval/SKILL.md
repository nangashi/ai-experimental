---
allowed-tools: Glob, Grep, Read, Write, Task, AskUserQuestion
description: Evaluate prompt effectiveness by generating structural variants and comparing their outputs
---

指定されたプロンプトファイルの構造的バリエーションを生成し、同一のテスト入力に対する出力を比較評価します。

## 使い方

```
/prompt_eval <プロンプトファイルパス>
```

引数がない場合は、ユーザーに対象プロンプトのファイルパスを質問してください。

## ワークフロー

以下の6フェーズを順に実行してください。

---

### Phase 1: 対象プロンプトの構造分析

**目的**: 対象プロンプトの構造次元を抽出し、バリエーション生成の基礎とする。

1. 対象プロンプトファイルを `Read` で読み込む
2. 以下の **6つの構造次元** について現状の水準を分析する:

| 構造次元 | 分析観点 |
|---------|---------|
| **見出し数** | トップレベルの評価カテゴリ・セクション数 |
| **サブ項目の粒度** | 各カテゴリ内の箇条書き項目の行数と項目数 |
| **出力形式の詳細度** | 出力テンプレート/フォーマット指定の構造化レベル |
| **原則/制約の明示度** | 禁止事項、ルール、原則の具体性と数 |
| **分析手順の有無** | ステップバイステップの手順指示があるか |
| **具体例の有無** | 出力例やFew-shot例が含まれるか |

3. 分析結果をテーブル形式で整理し、ユーザーに提示する

**出力**: 構造次元の分析テーブル（次元 / 説明 / 現状の水準）

---

### Phase 2: テスト入力の自動生成 + ユーザー確認

**目的**: 対象プロンプトの用途に合ったテスト入力と正解キーを自動生成する。

1. 対象プロンプトの用途（レビュー、計画作成、コード生成等）を特定する
2. その用途に対して **意図的に問題を埋め込んだテスト入力** を生成する
   - 問題は **10個** 埋め込む
   - カテゴリ（セキュリティ、パフォーマンス、設計原則、保守性、一貫性等）を分散させる
   - 深刻度（重大/中/軽微）を混在させる
   - 問題は自然に埋め込み、わざとらしくならないようにする
3. **正解キー**（各問題のID、カテゴリ、深刻度、該当箇所、期待される指摘、検出判定基準）を生成する
4. `AskUserQuestion` でユーザーに以下を確認する:
   - テスト入力の概要と埋め込んだ問題の一覧
   - 修正・追加したい問題があるか
   - テスト入力の品質に問題がないか

**出力**: テスト入力 (`test-input.md`) と正解キー (`answer-key.md`) の内容

---

### Phase 3: バリエーションの自動生成

**目的**: `variant-definitions.md` に基づいて10個のバリエーションを生成する。

1. `.claude/skills/prompt_eval/variant-definitions.md` を読み込む
2. Phase 1 の構造分析結果を参照し、各バリエーション（A〜J）について:
   - 定義された独立変数のみを変化させる
   - **独立変数以外の要素は元のプロンプトから変更しない**（統制変数の維持）
   - 変換ルールに従って具体的なプロンプトテキストを生成する
3. 生成する10バリエーション:

| ID | 名称 | 変化させる独立変数 |
|---|---|---|
| A | ベースライン | なし（元プロンプトをそのまま使用） |
| B | ミニマル | 全構造を最小化（役割+タスク+最小出力形式のみ） |
| C | 見出し削減 | カテゴリ数を約3つに統合 |
| D | 見出し拡張 | カテゴリ数を約8つに拡張 |
| E | 骨格のみ | サブ項目を全削除（見出しのみ残す） |
| F | 詳細記述 | サブ項目を大幅に拡充（問い+アンチパターン+判断基準） |
| G | 出力形式簡略 | 出力テンプレート削除（自由形式） |
| H | 分析手順明示（CoT） | 段階的分析ステップを追加 |
| I | 具体例付き（Few-shot） | 良い出力例を3つ追加 |
| J | 定量スコアリング | 数値評価基準（1-5点）を追加 |

**注意**: 各バリエーションの変換ルールの詳細は `variant-definitions.md` を参照すること。

**出力**: 10個のバリエーションプロンプト (`variant-a-baseline.md` 〜 `variant-j-scoring.md`)

---

### Phase 4: バリエーションの並列実行

**目的**: 10バリエーションをサブエージェントで並列実行する。

1. 10個のバリエーションを `Task` ツールで**並列に**実行する
   - 1つのメッセージで10個の `Task` ツール呼び出しを行う（ただしトークン制限を考慮し、必要に応じて2回に分割する）
   - 各サブエージェントには以下を渡す:
     ```
     [バリエーションのプロンプト本文]

     ---

     以下の入力に対してタスクを実行してください:

     [テスト入力の全文]
     ```
   - `subagent_type: "general-purpose"` を使用する
   - **全バリエーションで同じモデルを使用する**（`model: "sonnet"` を推奨）
2. 各結果をそのまま保存する（編集しない）

**出力**: 10個の実行結果 (`variant-a-result.md` 〜 `variant-j-result.md`)

---

### Phase 5: 採点・比較分析

**目的**: `scoring-template.md` に基づいて全結果を採点し、構造次元ごとの分析を行う。

1. `.claude/skills/prompt_eval/scoring-template.md` を読み込む
2. Phase 2 で生成した正解キーを参照し、各バリエーションの結果を採点する:
   - 各問題について `○`（検出）/ `△`（部分検出）/ `×`（未検出）を判定
   - 検出判定は正解キーの「検出判定基準」に従う
3. 定性指標（具体性、説明の質、構造性）を評価する
4. 誤検出（False Positive）の件数をカウントする
5. 以下の分析を行う:
   - **構造次元ごとの対比分析**: 各独立変数の変化が出力にどう影響したか
     - 見出し数: C vs A vs D
     - サブ項目粒度: E vs A vs F
     - 出力形式: G vs A vs J
     - 分析手順: A vs H
     - 具体例: A vs I
     - 全体量: B vs A vs F/D
   - **カテゴリ別の検出傾向**: どのカテゴリの問題がどのバリエーションで検出されやすいか
   - **深刻度別の検出傾向**: 重大/中/軽微の問題がどのバリエーションで検出されやすいか

**出力**: 採点結果と比較分析

---

### Phase 6: 結果の出力

**目的**: 全成果物を `prompt-eval/{timestamp}_{name}/` に保存する。

1. 出力ディレクトリを作成する:
   ```
   prompt-eval/{YYYYMMDD-HHMMSS}_{prompt-name}/
   ```
   - `{prompt-name}` はプロンプトファイル名（拡張子なし）
   - 例: `prompt-eval/20250615-143022_plan-architect/`

2. 以下のファイルを保存する:
   ```
   prompt-eval/{timestamp}_{name}/
   ├── test-input.md               # Phase 2 のテスト入力
   ├── answer-key.md               # Phase 2 の正解キー
   ├── variants/                   # Phase 3 のバリエーション
   │   ├── variant-a-baseline.md
   │   ├── variant-b-minimal.md
   │   ├── variant-c-heading-reduced.md
   │   ├── variant-d-heading-expanded.md
   │   ├── variant-e-skeleton.md
   │   ├── variant-f-detailed.md
   │   ├── variant-g-free-format.md
   │   ├── variant-h-cot.md
   │   ├── variant-i-fewshot.md
   │   └── variant-j-scoring.md
   ├── results/                    # Phase 4 の実行結果
   │   ├── variant-a-result.md
   │   ├── variant-b-result.md
   │   └── ...
   └── comparison-report.md        # Phase 5 の比較分析レポート
   ```

3. `comparison-report.md` は `scoring-template.md` の比較レポート構成テンプレートに従い、以下を含めること:
   - 実行条件（モデル、日時、対象プロンプト）
   - 採点マトリクス（10バリエーション × N問題）
   - 構造次元ごとの対比分析
   - カテゴリ別・深刻度別の検出傾向
   - 総合考察と推奨事項

4. ユーザーに完了を報告する:
   - 出力ディレクトリのパス
   - 最も検出率が高かったバリエーションとその特徴
   - 構造次元ごとの主要な知見（1-2行ずつ）
