# 自律型AIエージェントの性能向上：エビデンスベースの実装ガイド

Claude Codeのような自律型AIエージェントの性能は、モデル選択だけでなく**スキャフォールド設計によって最大10倍変動する**。Anthropicの検証では、同一モデル（Claude 3.5 Sonnet）でもスキャフォールドの違いにより500問中の正答が205問しか重複せず、残りは設計差で決まった。本レポートは、ワークフローオーケストレーション・サブエージェント戦略・リソース管理の3観点から、実装判断に使える定量エビデンス付きベストプラクティスを整理する。

---

## 1. ワークフローオーケストレーション：シンプルさが最高性能を生む

### 段階的パターン選択が性能とコストの両方を最適化する

Anthropicは2024年12月の「Building Effective Agents」で、エージェントワークフローを6段階のパターンに体系化した。核心原則は**「単純なプロンプトから始め、評価で最適化し、単純な方法で不十分な場合にのみ多段階エージェントを追加する」**ことである。

**プロンプトチェーニング**は最も推奨される起点パターンで、タスクを逐次的サブタスクに分解し、各LLMコールの間にプログラム的な検証ゲートを挿入する。各コールをより簡単なタスクにすることで、レイテンシを犠牲にして精度を高める。**ルーティング**は入力を分類し専門化されたハンドラに振り分けるパターンで、簡単なクエリをClaude Haikuに、難しいクエリをClaude Sonnetに割り振ることでコスト最適化を実現する。**並列化**はセクショニング（独立サブタスクの同時実行）とヴォーティング（同一タスクの複数回実行＋多数決）の2形態があり、コード生成と脆弱性チェックの同時実行などに適用される。

コーディングエージェントにとって最重要なのは**オーケストレータ・ワーカーパターン**である。中央LLMがタスクを動的に分解し、ワーカーLLMに委任して結果を統合する。並列化パターンとの決定的違いは、サブタスクが事前定義されない点にある。Anthropicはこのパターンを「複数ファイルに複雑な変更を加えるコーディング製品」に明示的に推奨しており、Claude Codeのマルチファイル編集機能の基盤アーキテクチャでもある。

### ReActと自己反省ループは統計的に有意な改善をもたらす

**ReAct（Reasoning + Acting）パターン**（Yao et al., ICLR 2023）は言語的推論トレースと行動・観察を交互に実行する手法で、現代のコーディングエージェントの基盤的パターンである。ALFWorldテキストゲームで既存手法に対して**+34%の成功率改善**、WebShopウェブナビゲーションで**+10%の改善**を達成した。最良の結果はReActとChain-of-Thought（CoT）の組合せで得られ、内部知識と外部情報の両方を活用できる。

**Reflexion**（Shinn et al., NeurIPS 2023）は環境フィードバックを言語的自己反省に変換し、次回試行のコンテキストとして格納する手法である。HumanEvalプログラミングタスクで**+11%（91% pass@1達成）**、AlfWorld意思決定タスクで**+22%**の改善を示した。Renze & Guven（2024）の追試では、テストした全9モデルにおいて全種類の自己反省が**統計的有意（p < 0.001）**で性能を改善し、GPT-4では基準78.6%から97.1%へ**+18.5ポイント**の向上を確認した。特筆すべきは、「以前のミスを知っている」という最小限の反省情報（Retry型）ですら有意な改善をもたらすことである。ただし、Reflexionは局所最適からの脱出が必要なタスクには弱く、WebShopでは4試行後に改善が停止した。

### 並列サンプリングと反復検証が最高スコアを達成する

**テスト時コンピュート拡大**は現在のSWE-benchトップスコアの鍵である。Anthropicの「高コンピュート」アプローチは、複数の並列試行からパッチを生成し、回帰テストで失敗するパッチを棄却し、スコアリングモデルで最良の結果を選択する。この手法によりClaude Sonnet 4.5のSWE-bench Verifiedスコアは**77.2%から82.0%に向上**した。

**Agentless**（Xia et al., 2024）は対照的に、階層的ローカリゼーション→修復→パッチ検証の3段階パイプラインという極めてシンプルな構造で、**エージェントベース手法の5〜10分の1のコスト（$0.34-$0.70 vs $3.34+/issue）**で競争力のある性能を実現した。Claude 3.5 Sonnetと組み合わせてSWE-bench Verifiedで50.8%を達成している。さらに、Kimi-DevはAgentless訓練で獲得したスキルプライオ（ローカリゼーション・修復・自己反省）がエージェント的実行にも転移することを示し、**60.4%**を記録した。

**Live-SWE-agent**（Xia et al., 2025年11月）は最小限のスキャフォールドから出発し、問題解決中に自律的にスキャフォールドを進化させる手法で、テスト時スケーリングなしで**SWE-bench Verified 77.4%、SWE-bench Pro 45.8%**（当時の最高）を達成した。

| 手法 | SWE-bench Verified | コスト/issue | 特徴 |
|------|-------------------|-------------|------|
| Agentless (GPT-4o) | 27.3% (Lite) | $0.34-0.70 | 最低コスト |
| Claude 3.5 Sonnet + Anthropic scaffold | 49.0% | — | シンプルスキャフォールド |
| Kimi-Dev (Agentless訓練) | 60.4% | — | ワークフロー→エージェント転移 |
| Live-SWE-agent + Gemini 3 Pro | 77.4% | — | 自己進化スキャフォールド |
| Claude Sonnet 4.5（単体） | 77.2% | — | 最小スキャフォールド |
| Claude Sonnet 4.5（高コンピュート） | 82.0% | — | 並列サンプリング+棄却+スコアリング |

---

## 2. サブエージェント戦略：タスク特性が最適アーキテクチャを決定する

### 並列可能タスクで+81%、逐次タスクで-70%という劇的な分岐

Google Researchの大規模実験（2026年1月公開、180構成×5アーキテクチャ×4ベンチマーク×3モデルファミリ）は、マルチエージェント設計の効果がタスク特性に決定的に依存することを実証した。**並列可能なタスク（Finance-Agent）では中央集権型が+80.9%の改善**を示した一方、**逐次依存タスク（PlanCraft）では全てのマルチエージェント変種が-39〜-70%の性能劣化**を引き起こした。

エラー増幅も重要な知見である。**独立型マルチエージェントはエラーを17.2倍に増幅**したのに対し、**中央集権型は4.4倍に抑制**した。タスク特性（ツール数、分解可能性）を入力とするR²=0.513の予測モデルは、未知タスクの**87%で最適アーキテクチャを正しく予測**した。このモデルにより、ツール数16以上のタスクではツール間協調オーバーヘッドが急増しマルチエージェントの利点が消失することが定量的に示された。

### Anthropicのマルチエージェント研究システムは+90.2%の改善を達成した

Anthropicが2025年6月に公開した本番マルチエージェント研究システムでは、Claude Opus 4のリードエージェントがClaude Sonnet 4の3〜5サブエージェントを並列で指揮するオーケストレータ・ワーカーアーキテクチャを採用している。**単一エージェントClaude Opus 4に対して内部研究評価で+90.2%の性能改善**を記録し、**並列ツール呼び出しにより複雑なクエリの研究時間を最大90%短縮**した。

重要な発見として、**トークン使用量がBrowseCompベンチマーク性能分散の80%を説明**し、ツール呼び出し回数とモデル選択が残り15%を説明した。つまり、研究・情報収集タスクでは「より多くのトークンを消費できること」自体が性能の主要ドライバーであり、マルチエージェントはその手段として機能する。ただし、マルチエージェントシステムはチャットの**約15倍のトークン**を消費するため、タスクの価値がコストを正当化する場合にのみ適用すべきである。

ツールテスト用エージェントがツール記述を改善した結果、**タスク完了時間が40%短縮**されたという知見も実用的に重要である。

### コーディングタスクではマルチエージェントに慎重であるべき理由

Cognition Labs（Devinの開発元）は2025年6月に「Don't Build Multi-Agents」と題したブログで、長時間稼働するコーディングエージェントにおけるマルチエージェントの根本的脆弱性を指摘した。論点は2つある。第一に、サブエージェントがメインエージェントの完全なトレースを共有しない場合、**ミスコミュニケーションが蓄積**する。第二に、並列エージェントが互いに矛盾する暗黙的決定を行い、**不整合な出力**を生成する。

この分析はClaude Codeの設計と整合する。**Claude Codeのサブエージェントはメインエージェントと並列で作業せず、明確に定義された質問への回答（探索・リサーチ）のみを担当し、コード記述は行わない**。これは暗黙的決定の競合を回避する設計である。

**AgentCoder**（ICLR 2024）は例外的にマルチエージェントがコーディングで有効なケースを示す。Programmer Agent、Test Designer Agent、Test Executor Agentの3エージェントによる反復フィードバックループで、HumanEvalで**96.3% pass@1**（先行技術90.2%）、MBPPで**91.8% pass@1**（先行技術78.9%）を達成した。決定的な設計ポイントは、テスト設計をコード生成から独立したエージェントに分離したことで、客観的かつ包括的なテストが生成される。さらに、MetaGPT（5エージェント、138.2Kトークン）やChatDev（7エージェント、183.7Kトークン）と比較して、AgentCoderは**3エージェント・56.9Kトークンでより高い性能**を達成しており、**エージェント数が少ないほど性能が高い**ケースを実証している。

### マルチエージェント適用の定量的判断基準

| 条件 | 推奨 | エビデンス |
|------|------|-----------|
| タスクが独立サブタスクに分解可能 | マルチエージェント | Google: +80.9% (Finance-Agent) |
| 幅広い情報収集が必要 | マルチエージェント | Anthropic: +90.2% (研究タスク) |
| コンテキストウィンドウを超える情報量 | サブエージェント分離 | 各サブエージェントが独立コンテキスト |
| 客観的検証が可能（テスト生成等） | 専門エージェント分離 | AgentCoder: +6% pass@1 |
| 逐次依存タスク | 単一エージェント | Google: -39〜-70%劣化 |
| 共有状態のあるコーディング | 単一エージェント | Cognition: 暗黙的決定の競合 |
| ツール数16以上 | 単一エージェント | Google: 協調オーバーヘッド急増 |
| コスト制約が厳しい | 単一エージェント | マルチエージェント = 15倍トークン |

---

## 3. リソース管理：KVキャッシュヒット率が最重要メトリクスである

### プロンプトキャッシュで90%コスト削減・85%レイテンシ削減

Anthropicのプロンプトキャッシュは、プロンプトの静的部分のKVテンソルを保存し再利用する機構で、キャッシュ済みトークンのコストは**$0.30/MTok vs 未キャッシュ$3.00/MTok（10倍差）**、TTFLレイテンシは**最大85%削減**される。キャッシュ書き込みは25%の上乗せがあるため、**2回のAPIコールで損益分岐**する。実例として、1リクエスト81,262トークンのYouTube分析ボットでは月額コストが**$720→$72（90%削減）**された。

「Don't Break the Cache」（arXiv:2601.06007）はOpenAI・Anthropic・Google横断で500以上のエージェントセッションを評価し、プロンプトキャッシュにより**APIコスト45-80%削減、TTFT 13-31%改善**を確認した。Anthropicの明示的キャッシュは100%ヒット率を達成する一方、OpenAIの自動キャッシュは約50%ヒット率にとどまる。

**Manus AIはKVキャッシュヒット率を「プロダクションエージェントの最重要メトリクス」と定義**している。エージェントの平均入出力トークン比が100:1であるため、プレフィックスキャッシュの影響は極めて大きい。Manusの実装原則は、(1) プロンプトプレフィックスの安定化（先頭にタイムスタンプを置かない）、(2) コンテキストのappend-only設計、(3) 決定的シリアライズ（`sort_keys=True`）、(4) ツール削除の代わりにロジットマスキング使用（キャッシュ無効化回避）、(5) 手動キャッシュブレークポイントの挿入、である。独立ベンチマークでは安定プレフィックスvs摂動プレフィックスで**レイテンシ64%改善・コスト71.3%削減**が確認され、1日10,000リクエスト規模で**年間約$237,500の削減**に相当する。

### コンテキスト圧縮は手法選択が性能を左右する

コンテキスト圧縮にはLLMベースの要約、観測マスキング、アクティブ圧縮、タスク対応圧縮の4手法があり、それぞれ異なるトレードオフを持つ。

**LLMベースの要約（コンテキスト凝縮）**はOpenHands、Claude Code、Cursor等が採用する標準手法である。OpenHandsの検証では、SWE-bench Verifiedにおいて**トークン消費・コスト・完了時間を全て削減しつつ解決率を同等以上（54% vs 53%）に維持**した。Claude Codeは**コンテキスト利用率83.5%（200Kトークン中167K）で自動圧縮を発動**し、約33Kトークンを要約処理に確保して**4-10倍のトークン削減**を実現する。

**観測マスキング**（JetBrains Research, NeurIPS 2025ワークショップ）は、古いターンの観測部分のみをマスクし、推論と行動の履歴は完全に保持する手法である。エージェントの観測（テストログ、ファイル読み取り結果）が最大のトークン消費源であるため、この手法は効率的にコンテキストサイズを削減する。マスキングと選択的要約のハイブリッドが最良のコスト・性能トレードオフを達成した。

**アクティブコンテキスト圧縮**（arXiv:2601.07190の「Focus」手法）は、エージェント自身が10-15ツール呼び出しごとにコンテキストを圧縮し、持続的な「知識ブロック」を維持する。SWE-benchの困難な5インスタンスで**平均22.7%のトークン削減**、最良ケースで**57%削減（4.0M→1.7Mトークン）**を達成し、精度は同一（3/5=60%）を維持した。ただし、1/5のケースでは圧縮が再探索を引き起こし使用量が110%増加しており、反復的タスクでは普遍的に有効ではない。

**ACON（Agent Context Optimization）**（arXiv:2510.00615）はタスク対応・失敗駆動型の圧縮ガイドライン最適化フレームワークで、**ピークトークン26-54%削減**を精度維持または改善しつつ達成した。蒸留された圧縮器は教師の性能の**95%以上を保持**する。

**SWE-Pruner**（arXiv:2601.16746）はファイル読み取りを傍受しタスク対応プルーニングを適用するミドルウェアで、SWE-bench Verifiedで**23-38%トークン削減、精度劣化1%未満**、インタラクションラウンド**18-26%削減**を達成した。

### ツール管理とコードベースインデキシングの最適化

ツール管理では、**ツール数の削減が実行時間最大70%短縮・消費電力40%削減**をもたらす（arXiv:2411.15399）。Manusは3階層ツールアーキテクチャ（Level 1: 約20の安定コアツール、Level 2: CLI経由のサンドボックスユーティリティ、Level 3: 動的コード/パッケージ）を採用しており、100以上のツールを提供するとパラメータのハルシネーションや誤ったツール選択が発生する「Context Confusion」を回避している。Claude Codeでは、MCPツール定義がコンテキストウィンドウの10%を超える場合、自動的にツールを遅延読み込みし、オンデマンドでツール検索を行う。

コードベースインデキシングでは、**AST（抽象構文木）ベースのチャンキング**（cAST, arXiv:2506.15655）がナイーブな行ベース分割を大幅に上回る。RepoEval検索で**Recall@5が+4.3ポイント**、SWE-bench生成で**Pass@1が+2.67ポイント**改善した。ノードベースコンテキストはチャンクベースと比較してDevEvalのPass@1を**ほぼ2倍（16.67% vs 8.46%）**にした。さらに、Meta-RAG for Code（arXiv:2508.02611）は生コードの代わりに自然言語サマリを生成し、コードベースサイズを約80%削減しつつ、ファイルレベルバグローカリゼーション精度**84.67%（BM25ベースライン60%の1.4倍）**を達成した。Windsurfのアプローチは埋め込み検索・grep・知識グラフ・AST解析を組み合わせて、単一手法比**3倍の検索精度**を実現している。

### 階層的圧縮閾値によるコンテキスト寿命の最大化

コンテキストウィンドウの管理には段階的な閾値設計が有効である。LoCoBench-Agent（arXiv:2511.13998）は3段階のシステムを提案する。**早期警告（容量40%）** では非アクティブファイルを構造的サマリに圧縮する。**危機的（60%）** では古い会話ターンをLLMで要約する。**緊急（95%）** では最初の2ターンと最後の3ターンのみ原文保持し、残りを積極圧縮する。

Anthropicとchromaの研究によれば、コンテキストは「収穫逓減する有限リソース」として扱うべきである。トークン間のn²のペアワイズ関係により、コンテキスト増大に伴い注意が「薄く引き伸ばされる」。Manusは「Pre-Rot Threshold」を定義しており、1Mコンテキストのモデルでは**約256K付近から性能劣化**が始まるため、その前に圧縮を実施すべきとしている。圧縮の優先順位は**生コンテキスト > 観測マスキング > 要約**の順であり、最後の3ターンは常に原文形式で保持してモデルの出力品質を維持する。

---

## 結論：実装判断のための統合フレームワーク

本調査から、3つの横断的な原則が浮かび上がる。

第一に、**複雑さは性能の敵である**。Anthropicの最小スキャフォールド（BashツールとEditツールのみ）がSWE-bench 77.2%を達成し、Agentlessの3段階パイプラインが10分の1のコストで競争力を維持する。エージェント数の増加は性能を保証せず、AgentCoderの3エージェントがChatDevの7エージェントを上回る。実装者はまず最もシンプルなパターンから開始し、定量的評価で不十分と証明された場合にのみ複雑化すべきである。

第二に、**タスク特性がアーキテクチャを規定する**。Google Researchの実験が示す通り、並列可能タスクと逐次タスクでマルチエージェントの効果は+81%から-70%まで正反対に振れる。コーディングタスクでは共有状態の競合があるため単一エージェント＋探索用サブエージェントが最適解であり、研究・情報収集タスクではマルチエージェントが90%以上の改善をもたらす。この判断を自動化するR²=0.513の予測モデルが存在し、87%の精度で最適アーキテクチャを特定できる。

第三に、**KVキャッシュヒット率が費用対効果の支配的因子である**。エージェントの入出力トークン比100:1という特性上、プレフィックスキャッシュの効果は通常のLLMアプリケーションを大幅に上回る。安定プレフィックス設計・append-onlyコンテキスト・決定的シリアライズという3つの実装原則を遵守するだけで、コスト71%削減・レイテンシ64%改善が実現する。これはモデル変更やアーキテクチャ再設計を必要とせず、最も費用対効果の高い最初の最適化対象である。