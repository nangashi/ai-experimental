# Instruction Extract: context-design

source: /home/toyama-ryosuke/ghq/github.com/nangashi/ai-experimental/docs/knowledge/context-design.md
extracted: 2026-02-16
items: 11

---

## KE-001: コンテキスト改善をテクニック工夫より優先する

- **use-when**: Designing or restructuring agent/reviewer prompt structure (decomposition, technique selection, bias avoidance)
- **scope**: プロンプトエンジニアリングとコンテキストエンジニアリングの選択
- **action**: 言葉遣いや構造のテクニックを工夫する前に、まずタスクに必要な情報をコンテキストに提供することを優先する。
- **rationale**: プロンプトエンジニアリング改善の85%はコンテキスト改善で達成可能。適切な情報を提供することがテクニック選択より高い効果を持つ。

---

## KE-002: コンテキストはJust-in-Time戦略で構築する

- **use-when**: スキルやマルチステップのAIワークフローを設計するとき
- **scope**: RAG、ツール出力、メモリ等の動的コンテキスト管理
- **action**: 全データを事前ロードせず、基本コンテキストのみ事前取得し、追加探索は必要時に実行するハイブリッドアプローチを採用する。
- **rationale**: 全データの事前ロードは無関係な情報でコンテキストを汚染し精度を低下させる。必要時の動的ロードでコンテキストを効率的に管理できる。

---

## KE-003: 重要な指示は先頭と末尾に配置する

- **use-when**: Designing or restructuring agent/reviewer prompt structure (decomposition, technique selection, bias avoidance)
- **scope**: 複数の情報ブロックをコンテキストに配置する場合
- **action**: 最重要な指示・コンテキストをプロンプトの先頭と末尾に配置し、無関係なコンテキストを積極的に除去する。
- **rationale**: Chroma Researchの18 LLM評価で、位置1の事実は約75%精度、位置10は約55%精度と位置依存性が実証された。わずか20件の検索文書（約4,000トークン）で精度が70-75%から55-60%に低下する。情報の存在だけでなく、どのように、どこに提示されるかがより重要。

---

## KE-004: 長いワークフローにリセットポイントを設計する

- **use-when**: スキルやマルチステップのAIワークフローを設計するとき
- **scope**: 複数ターンで情報を蓄積するタスク
- **action**: 蓄積された決定事項を統合し、新鮮な単一プロンプトとして新しいインスタンスに送信する「リセットポイント」を設計する。
- **rationale**: 200,000+のシミュレーション会話で、シングルターンからマルチターンへの移行で平均39%の性能低下が確認された。Concat-and-Retry手法で精度が90%超に回復し、シングルターン性能にほぼ一致する。Claude Codeのauto-compactionはこの形式化に相当する。

---

## KE-005: 要件が揃うまで完全な解決策を提示しない指示を含める

- **use-when**: Designing or restructuring agent/reviewer prompt structure (decomposition, technique selection, bias avoidance)
- **scope**: 要件が複数ターンで段階的に明らかになるタスク
- **action**: 「すべての要件が提示されるまで完全な解決策を提案しない」という明示的な指示をプロンプトに含める。
- **rationale**: マルチターン劣化の主原因の1つは「早期解決試行」（要件が揃う前に仮定を置いて完全な回答を生成）。この指示により仮定の蓄積と誤ったアンカリングを防止できる。

---

## KE-006: 2回の修正失敗後は新規セッションで書き直す

- **use-when**: スキルやマルチステップのAIワークフローを設計するとき
- **scope**: 同一セッション内で修正を繰り返す場合
- **action**: 2回の修正失敗後は、セッションを新規にして書き直す。
- **rationale**: マルチターン劣化の「回答アンカリング」により、過去の誤った回答に依存し肥大化した回答が生成される。新規セッションで書き直す方が効率的。

---

## KE-007: ツール出力は全体でなく関連部分のみ保持する

- **use-when**: スキルやマルチステップのAIワークフローを設計するとき
- **scope**: ファイル内容、検索結果、API応答等の大きなツール出力
- **action**: ツール出力の全体をコンテキストに入れるのではなく、関連部分のみを選択的に保持する（観察マスキング）。
- **rationale**: Riceプラットフォームで長期記憶+短期状態管理の統合によりコンテキスト消費60%削減を達成。不要部分を除去することで完全な情報を保持しつつ不要なトークン消費を防ぐ。Cursor, Warpが採用するより洗練されたアプローチ。
- **conditions**: 要約アプローチは実装が簡単だが、詳細が失われるリスクがある。詳細が重要なタスクでは観察マスキングを優先すべき。

---

## KE-008: MCPツールは使用頻度とコンテキストコストを評価する

- **use-when**: スキルやマルチステップのAIワークフローを設計するとき
- **scope**: 複数のMCPツールを同時に使用する場合
- **action**: MCPツール定義のコンテキストコスト（数千トークン）を認識し、使用頻度の低いツールはJust-in-Timeでロードする。
- **rationale**: MCPツール定義がコンテキストウィンドウの一定割合を常に消費し、ツールが多いほどコンテキストの実効サイズが小さくなる。コスト対効果を評価すべき。

---

## KE-009: 指示ファイルは削除テストで最小化する

- **use-when**: Designing or restructuring agent/reviewer prompt structure (decomposition, technique selection, bias avoidance)
- **scope**: 永続的な指示ファイルの作成・編集
- **action**: 各行について「これを削除するとClaudeがミスするか？」と問い、NOなら削除する。コードを読めば分かること、標準的な言語規約、詳細なAPIドキュメント、「クリーンなコードを書け」等の自明な指示を含めない。
- **rationale**: Anthropic公式のCLAUDE.mdベストプラクティス。肥大化したCLAUDE.mdファイルはClaudeに実際の指示を無視させる。

---

## KE-010: コンテキスト更新は全面書き換えでなくインクリメンタルに行う

- **use-when**: スキルやマルチステップのAIワークフローを設計するとき
- **scope**: セッション間で蓄積される知識・教訓の管理
- **action**: 全面書き換えではなく、構造化デルタ更新、決定論的マージ、重複排除、プルーニングによるインクリメンタル更新を採用する（grow-and-refine原則）。
- **rationale**: ACEフレームワークの定量結果でエージェントタスク+10.6%、金融タスク+8.6%、適応レイテンシ82-92%削減、トークンコスト75-84%削減を達成。「簡潔化バイアス」（ドメイン洞察を要約のために削除）と「コンテキスト崩壊」（反復的書き換えで詳細が劣化）を防止する。

---

## KE-011: 永続メモリと一時結果を分離保存する

- **use-when**: スキルやマルチステップのAIワークフローを設計するとき
- **scope**: 学習能力を持つコーディングエージェントのメモリ設計
- **action**: `memory/`（永続的事実）と`outputs/`（一時的結果）を分離する。永続メモリはコンテキストウィンドウの外に保存し、関連するものだけロードする。
- **rationale**: 3層アーキテクチャ（Hooks層/Working Memory層/Long-term Knowledge層）により、セッション内の状態とセッション間の知識を分離管理できる。コンテキストウィンドウの効率的利用が可能になる。
