---
scope: LLMへの指示の書き方
boundary: |
  LLMへの指示の書き方を対象とする。
  モデルに渡す情報の選別・配置・圧縮は対象外。
  LLM出力の評価・採点の仕組み設計は対象外。
research_query: LLMへの指示の書き方に関して、性能に影響を与える技法・構造・形式の研究データと実践知見
---

# LLMへの指示の書き方

LLMへの指示の書き方に関する研究・実践知見。

## 基本テクニックの効果とモデル世代依存性

### Chain-of-Thought (CoT)

Wharton大学の研究(2025)により、CoTの効果がモデル進化とともに低下していることが明らかになった。

| モデル種別 | 平均改善 | 応答時間増加 |
|-----------|---------|------------|
| 非推論モデル (GPT-4o-mini等) | +4.4〜13.5% | +35〜600% |
| 推論モデル (o3-mini, o4-mini等) | +2.9〜3.1% | +20〜80% |
| Gemini Flash 2.5 (推論) | **-3.3%** | 大幅増 |

**有効な場面**: 複雑な多段推論、非推論モデル、柔軟なガイダンス形式（"Think through the design holistically"のように方向性のみ示す）

**逆効果な場面**: 剛性的ステップ指定（"Step 1:... Step 2:..."）はステップ完了バイアスで探索を抑制する。推論モデルは内部で既にCoT的処理を行うため明示的指示は冗長。簡単な問題では本来正答できるものを誤答にする変動性を導入する。

### Few-Shot

依然として最も強力なテクニックの1つだが、重要な条件がある。

**有効な場面**: 出力フォーマットの明示が必要なタスク（精度0%→90%の改善事例）、専門分野での例示、非推論モデル

**逆効果な場面**: 推論モデル（5-shotでベースラインより劣化）、複雑なレビュー・評価タスク（テンプレートバイアスで6例使用時に重大検出率100%→0%）、例が多すぎる場合（2例が最適、それ以上は満足化バイアス）

**ベストプラクティス**: ゼロショットで十分なら使わない（特に推論モデル）。例は1-2例。タスク難易度に合った例を選択する。

### ロール/ペルソナ

2025年の複数研究で厳しい再評価がなされている。

- 4モデルファミリー × 2,410事実質問テスト → 単純ペルソナは改善なし、時に劣化
- GPT-4-turbo × 2,000 MMLU問題 × 12ペルソナ → 「バカ」ペルソナが「天才」を上回る
- GPT-4レベル以降ではベースラインとの差がほぼゼロ

**有効な場面**: 創作・オープンエンドタスク（トーン・スタイル制御）、一貫性検証（パターン照合視点の強制、+3.0pt）

**使う場合**: 単純な"You are a lawyer"ではなく詳細かつドメイン固有の記述にする。LLM生成ペルソナが人間作成のものを上回る。

## 高効果テクニック

### 分解 (Decomposition)

複雑な問題をサブ問題に分解するアプローチは一貫して有効。

- カテゴリ別分解（ドメイン別）→ 安定性最高（SD=0.0）
- 検出と報告の分離 → +2.0〜2.5pt、早期フィルタリング防止
- エージェント的設定での逐次的推論に特に有効

### 自己批判 (Self-Criticism)

モデルに自身の出力を評価させるメタ認知的アプローチ。外部フィードバックループなしで精度向上。Self-Consistencyの発展形として、複数の推論パスを生成し最も一致する回答を選択する手法がある。

### アンサンブル

複数プロンプトの結果を組み合わせて信頼性向上。Self-Consistency（複数推論パスから最頻回答を選択）は算術・常識推論で特に有効。コスト増加とのトレードオフを考慮。

### 感情的刺激 (EmotionPrompt)

心理学的な感情的手がかりをプロンプトに織り込む手法。

- BIG-Benchタスクで**115%の改善**、大規模モデルほど恩恵が大きい
- "Take a deep breath and work on this problem step-by-step" → 汎用ステップバイステップより効果的
- タスクに応じた使い分け: バグ修正には緊急性、ブレストには興奮、助言には共感
- **注意**: ポジティブ刺激は追従的行動(sycophancy)も増加させる。最新モデルでは脅迫的表現は無効化済み

## 構造化の逆U字カーブと形式選択

### 構造化の量と性能の関係

構造化の量と性能は逆U字の関係にある。

- **最適点**: カテゴリ分解 → 系統性と探索性を両立
- **過剰構造化は一貫して逆効果**: チェックリスト統合(-1.75pt)、厳格カテゴリ(-4.5pt)
- 軽量ヒント2件が最適閾値、3件以上で逆効果

### 出力形式の選択

| 形式 | 適用場面 | 注意点 |
|------|---------|--------|
| XML | Claude系でのタグ区切り、命令的/ネスト構造 | Claudeはタグ区切り解釈に特に強い |
| JSON | データ抽出、分類、自動化、プログラム連携 | Structured Outputsでスキーマ準拠を保証可能 |
| 自然言語 | 推論の質が重要なタスク | フォーマット制約は推論能力を低下させる |

フォーマット制約が厳しいほど推論能力の低下が大きい。推論精度最優先なら、自然言語で回答させ後からフォーマット変換するNL-to-Formatアプローチが有効。

### Structured Outputs

- プロンプトエンジニアリング単体では35.9%の信頼性 → Structured Outputsで100%
- スキーマドリフトが壊れた自動化の最大原因 → スキーマ強制で防止
- 重要なプロンプトには自己チェックブロックを付加して出力フォーマット準拠を検証させる

## 推論時コンピュート拡張

推論時により多くの計算リソースを使い出力品質を向上させるアプローチ。

### スケーリング方式

| 方式 | 説明 | 代表手法 |
|------|------|---------|
| 並列 | 複数出力を並列生成→集約 | Self-Consistency、Best-of-N |
| 逐次 | 中間ステップに基づいて後続計算を誘導 | CoT、思考トークン |

### 主要手法

- **Budget Forcing**: "Wait"トークンでモデルの思考時間を制御
- **Self-Consistency**: 複数回答の多数決 → 算術・常識推論で4倍以上の効率改善
- **Tree of Thought (ToT)**: 分岐する推論パスを探索・評価・バックトラッキング
- **Adaptive Thinking (Claude 4.6)**: `thinking: {type: "adaptive"}` でクエリ複雑度に応じた動的思考。Extended Thinkingより一貫して高性能

### 実用知見

- 14倍大きいモデルをFLOPs一致評価で上回る場合あり
- 単一のTTS戦略が普遍的に優位ではない → タスク難易度と問題タイプに依存
- **推論強化はキャリブレーションを悪化させる**: 84.3%のシナリオで過信。「より深く考えさせる」と信頼度推定がより不正確になる
- **ディストラクター効果**: もっともらしい誤答選択肢を明示的に含めると精度最大460%改善、キャリブレーション誤差90%減少

## 自動プロンプト最適化

| フレームワーク | アプローチ | 特徴 |
|-------------|----------|------|
| DSPy | プログラミングベース | プロンプトでなくコードとしてLLM処理を定義。命令チューニング+例選択の同時最適化 |
| OPRO | LLMによる最適化 | プロンプト最適化をブラックボックス問題として扱い、LLMで候補生成・探索 |
| EvoPrompt | 進化的アルゴリズム | 遺伝的操作で世代を通じてプロンプトを進化 |

手動改善→自動最適化の順序が効率的。良い評価メトリクスが定義できる場合に有効。プロダクション用プロンプト（1日数十万回実行）で投資対効果が高い。

## Claude 4.x固有の設計指針

**明示的指示**: Claude 4.xは指示を文字通りに解釈する。以前のモデルは曖昧な指示から意図を推測して拡張したが、現行モデルは要求されたことだけを正確に実行する。"above and beyond"な動作を望む場合は明示的に要求する必要がある。

**理由の提供**: 「省略記号を使うな」ではなく「テキスト読み上げエンジンが処理できないため」と理由を述べるとモデルが汎化する。

**Prefill廃止 (Claude 4.6)**: 最後のアシスタントターンのプリフィルが非サポートに。代替として、出力フォーマット制御にはStructured Outputs、前文排除には"Respond directly without preamble"の直接指示を使用する。

**ツール並列実行**: 独立した操作は並列化を明示する。Opus 4.6はサブエージェント生成傾向が強く、単純タスクでの過剰委譲に注意。

## 普遍的原則

- **明確さ > 巧みさ**: プロンプト失敗の大半は曖昧さに起因し、モデルの限界ではない
- **言語一貫性**: 完全英語 or 完全日本語。混合は検出パターンシフトと安定性悪化を引き起こす
- **「何をしないか」より「何をするか」**: 禁止指示より代替行動の指示が効果的
- **不確実性の明示許可**: モデルに「わからない」と言う許可を与えることでハルシネーション減少
- **テクニックのモデル依存性**: CoT、Few-shot等の効果はモデル世代で大きく変わる。常に検証する
- **コンテキスト提供が先**: プロンプトテクニックの前にまず適切な情報を提供する。改善の85%はコンテキスト改善で達成可能（→「LLMに渡すコンテキストの設計と管理」で詳述）
