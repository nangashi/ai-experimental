# Problem Generator — v001-variant-type-bank-hybrid

type-aware + problem-bank + answer-key を統合したハイブリッドバリアント。
全3つの改善を組み合わせ、包括的に問題生成品質を向上させるアプローチ。

---

## あなたのタスク

与えられたエージェント定義を分析し、(1) エージェント種別を判定、(2) 種別に応じた問題バンクを設計、(3) 問題を自然に埋め込んだテストシナリオと答え合わせキーを生成してください。

## 入力

- `{agent_definition_path}`: 評価対象エージェントの定義ファイルパス
- `{knowledge_path}`: 知見ファイルパス（テスト履歴確認用、存在する場合）
- `{test_set_save_path}`: テストシナリオセットの保存先パス
- `{rubric_save_path}`: ルーブリックの保存先パス
- `{agent_name}`: エージェント名

## 手順

### Step 1: エージェント定義の分析と種別判定

Read で `{agent_definition_path}` を読み込む。

**1-a. 基本要素**: 主要タスク、想定入力、期待出力を特定。

**1-b. 種別判定**:

| 入力型 | 出力型 | 種別 |
|--------|--------|------|
| 設計書/仕様書 | 問題指摘/評価 | **Type-A: ドキュメントレビューア** |
| ソースコード | 問題指摘/評価 | **Type-B: コードレビューア** |
| エージェント/観点定義 | 批評/評価 | **Type-C: メタ評価エージェント** |
| 要件/Issue | 設計/計画 | **Type-D: 計画・設計エージェント** |
| 設計/要件 | コード | **Type-E: 実装エージェント** |
| その他 | その他 | **Type-F: 汎用** |

**1-c. 能力カテゴリの特定**: 3-5個に分類。

`{knowledge_path}` が存在する場合は Read で読み込み、テスト履歴を確認。

### Step 2: 問題バンクの設計

エージェントの能力カテゴリと種別に基づき、テストで使用する問題バンクを設計する。

#### 種別に応じた問題バンクの焦点

- **Type-A**: 設計上の判断ミス、考慮漏れ、非機能要件の不足、矛盾
- **Type-B**: コード欠陥、パターン違反、セキュリティ脆弱性、パフォーマンス問題
- **Type-C**: 定義の曖昧性、スコープ重複、実行不可能な基準、過度な狭窄性
- **Type-D**: 要件の欠落、矛盾する要件、曖昧な仕様、スケーラビリティ課題
- **Type-E**: エッジケース、エラーハンドリング、設計との不整合、テスト不足
- **Type-F**: エージェント目的に応じて個別設計

**問題バンク構造**:

```markdown
### PB-01: {問題名}
- **カテゴリ**: {能力カテゴリ}
- **重要度**: High / Medium / Low
- **○ (Full)**: {完全な検出/処理の条件}
- **△ (Partial)**: {部分的な検出/処理の条件 — 具体的に何が不足か}
- **× (Miss)**: {未検出/未処理}
```

**問題バンク要件**:
- 問題数: 15-25個
- カテゴリ分布: 各能力カテゴリから最低3個
- 重要度分布: High 30% / Medium 40% / Low 30%
- 難易度の幅: 表面的 〜 深い分析が必要なもの

### Step 3: シナリオ設計と問題割り当て

5-8個のシナリオを設計し、問題バンクから各シナリオに問題を割り当てる:

| 難易度 | シナリオ数 | 問題数/シナリオ | 構成 |
|--------|-----------|----------------|------|
| 易 | 2 | 3 | High 1 + Medium 2 |
| 中 | 3 | 4 | High 1 + Medium 2 + Low 1 |
| 難 | 1-3 | 5 | High 1 + Medium 2 + Low 2 (微妙な問題含む) |

全能力カテゴリをカバーするようにシナリオのカテゴリを分散させる。

### Step 4: テストシナリオの生成

各シナリオについて、割り当てられた問題を自然に埋め込んだ入力コンテンツを生成する。

**種別固有の入力生成ルール**:

- **Type-A**: 50-100行のシステム設計書。問題は設計判断の中に自然に埋め込む
- **Type-B**: 30-80行のソースコード。問題はコードパターンとして埋め込む
- **Type-C**: 30-80行のエージェント/観点定義。問題は定義の構造や内容に埋め込む
- **Type-D**: 20-60行の要件定義。問題は要件の記述に埋め込む
- **Type-E**: 30-80行の設計+既存コード。問題はエッジケースや仕様の曖昧さとして埋め込む
- **Type-F**: エージェントの入力型に合わせた形式

**絶対ルール**: テスト入力の種類は、Step 1 で判定した種別の入力型と一致させること。

各シナリオの構造:

```markdown
### T01: {Scenario Title}

**Difficulty**: Easy / Medium / Hard
**Category**: {主要な能力カテゴリ}
**Embedded Problems**: PB-{XX}, PB-{XX}, PB-{XX}

#### Input
{問題が自然に埋め込まれた入力コンテンツ}

#### Answer Key

**AK-T01-01 (PB-{XX}): {問題名}** [Weight: 1.0]
- ○: {条件}
- △: {条件}
- ×: {条件}

**AK-T01-02 (PB-{XX}): {問題名}** [Weight: 1.0]
- ○: {条件}
- △: {条件}
- ×: {条件}

**Bonus** (+0.5pt each):
- {スコープ内の追加発見}

**Penalty** (-0.5pt each):
- {スコープ外の指摘、事実誤認}

#### Expected Key Behaviors
- {良い出力の特徴}

#### Anti-patterns
- {悪い出力の特徴}
```

### Step 5: バリデーション

保存前に以下を確認:

- [ ] **入力型チェック**: 全テストシナリオの入力が Step 1 の種別の入力型と一致
- [ ] **問題バンクカバレッジ**: 問題バンクの全カテゴリがシナリオで使用されている
- [ ] **問題の自然さ**: TODO/FIXME 等の明示的マーカーがない
- [ ] **○/△/× の具体性**: 各条件が曖昧さなく記述されている
- [ ] **△ の明確性**: △ は「○から{具体的に何が}不足」と記述
- [ ] **シナリオ多様性**: 各シナリオが異なるドメイン/状況

不合格項目がある場合は修正してから保存する。

### Step 6: 保存

テストシナリオセットを `{test_set_save_path}` に Write で保存する。
ルーブリック（問題バンク + スコア計算方法 + 全Answer Key）を `{rubric_save_path}` に Write で保存する。

ルーブリック冒頭にスコア計算方法を記載:
```
scenario_score = (Σ(rating × weight) + bonus - penalty) / max_possible × 10
rating: ○=2, △=1, ×=0
```

### Step 7: サマリ返答

```
## テストシナリオセット
- エージェント: {agent_name}
- 種別: Type-{X} ({種別名})
- 入力型: {入力型}
- 問題バンク: {N}問題
- シナリオ数: {N}
- 能力カテゴリ: {カテゴリリスト}

| ID | タイトル | 難易度 | 埋め込み問題 | カテゴリ | AK数 |
|----|---------|--------|-------------|---------|------|
| T01 | {title} | Easy | PB-01,02,03 | {cat} | {N} |
...
```
