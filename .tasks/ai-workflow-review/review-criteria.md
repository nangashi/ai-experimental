# AIワークフロー設計レビュー観点

ソース: docs/research/ai-workflow-research.md
フォーマット設計根拠: .tasks/ai-workflow-review/format-design.md

---

## 1. ワークフローパターン選択

### WF-01: 最小パターンからの段階的複雑化

- **check**: 最もシンプルなパターン（プロンプトチェーニング）から開始し、定量評価で不十分と証明された場合にのみ複雑なパターンを追加しているか？
- **scope**: 新規ワークフロー設計・タスク分解アーキテクチャの選定
- **action**: 単純なプロンプトチェーニングから始め、各段階でベンチマーク評価を行い、不十分な場合のみルーティング→並列化→オーケストレータ・ワーカーへ段階的に移行する
- **rationale**: Anthropicの最小スキャフォールド（Bash+Editのみ）がSWE-bench 77.2%を達成。AgentCoderの3エージェントがChatDevの7エージェント（183.7Kトークン）を56.9Kトークンで上回る
- **improvement**: コスト5-10分の1削減（Agentless: $0.34-0.70 vs エージェントベース: $3.34+/issue）。不要な複雑化の回避
- **severity**: critical

### WF-02: マルチファイル変更へのオーケストレータ・ワーカー適用

- **check**: 複数ファイルへの複雑な変更を行うタスクに対して、サブタスクを動的に分解するオーケストレータ・ワーカーパターンを使用しているか？
- **scope**: 複数ファイルにまたがる変更を含むコーディングタスク
- **action**: 中央LLMがタスクを動的に分解し、ワーカーLLMに委任して結果を統合する構成にする。並列化パターン（事前定義サブタスク）との違いは、サブタスクが動的に決定される点
- **rationale**: Anthropicが「複数ファイルに複雑な変更を加えるコーディング製品」に明示的に推奨。Claude Codeの基盤アーキテクチャ
- **improvement**: 事前に予測できないサブタスクへの柔軟な対応が可能
- **severity**: major

### WF-03: ReAct（推論+行動）パターンの採用

- **check**: ツール使用を伴うタスクで、推論トレース→行動→観察の交互実行パターンを採用しているか？
- **scope**: ツール呼び出しと推論を組み合わせるエージェントタスク
- **action**: 言語的推論トレースと行動・観察を交互に実行するReActパターンを採用する。Chain-of-Thoughtとの組み合わせで内部知識と外部情報の両方を活用する
- **rationale**: ALFWorldで+34%、WebShopで+10%の成功率改善（Yao et al., ICLR 2023）。現代のコーディングエージェントの基盤的パターン
- **improvement**: +10〜34%の成功率改善（タスク種別依存）
- **severity**: major

### WF-04: 環境フィードバックの自己反省ループ

- **check**: テスト失敗やエラーログ等の環境フィードバックを言語的反省に変換し、次回試行のコンテキストとして格納しているか？
- **scope**: 反復改善タスク（テスト駆動開発、バグ修正、リトライ処理）
- **action**: 環境フィードバックを言語的自己反省に変換し、次回試行のコンテキストとして格納する。最小限の反省情報（「以前のミスを知っている」等のRetry型）から開始し、不十分な場合に詳細化する
- **rationale**: テストした全9モデルで統計的有意（p<0.001）。GPT-4で基準78.6%→97.1%（+18.5pt）。最小限のRetry型反省でも有意な改善。ただしWebShopでは4試行後に改善停止（局所最適の限界）
- **improvement**: +11〜18.5%の精度向上
- **severity**: major

### WF-05: 高品質要求時の並列サンプリング+棄却

- **check**: 品質が最優先のタスクで、複数の並列試行→テストによる棄却→スコアリングで最良選択の手法を検討しているか？
- **scope**: 品質が最優先でコスト制約が緩いタスク（本番デプロイ前の修正等）
- **action**: 複数の並列試行でパッチを生成し、回帰テストで失敗パッチを棄却し、スコアリングモデルで最良結果を選択する
- **rationale**: Claude Sonnet 4.5のSWE-bench Verifiedスコアが単体77.2%→高コンピュート82.0%に向上。テスト時コンピュート拡大が現在のトップスコアの鍵
- **improvement**: +4.8%の精度向上（SWE-bench Verified）
- **severity**: minor

### WF-06: エージェントレスアプローチの事前検討

- **check**: エージェント的手法を採用する前に、シンプルなパイプライン（ローカリゼーション→修復→検証）で十分かを検討しているか？
- **scope**: バグ修正・コード修復タスクのアーキテクチャ選定
- **action**: まず階層的ローカリゼーション→修復→パッチ検証の3段階パイプライン（Agentlessアプローチ）を検討し、不十分な場合にエージェント的手法へ移行する
- **rationale**: Agentlessがエージェントベース手法の5-10分の1のコスト（$0.34-0.70 vs $3.34+/issue）で競争力のある性能を実現。Kimi-DevはAgentless訓練スキルがエージェント的実行にも転移し60.4%を達成
- **improvement**: コスト5-10分の1削減。パイプライン訓練スキルのエージェント転移も可能
- **severity**: major

---

## 2. サブエージェント設計

### SA-01: タスク分解可能性の事前評価

- **check**: マルチエージェント構成を採用する前に、タスクが独立サブタスクに並列分解可能であることを確認しているか？
- **scope**: マルチエージェントアーキテクチャの採用判断
- **action**: タスクの分解可能性を事前に評価する。並列可能タスクにはマルチエージェント、逐次依存タスクには単一エージェントを選択する。判断基準：タスク間に状態依存があるか、サブタスクの出力が他のサブタスクの入力となるか
- **rationale**: Google Research大規模実験（180構成×5アーキテクチャ×4ベンチマーク×3モデル）：並列可能タスクで+80.9%改善、逐次依存タスクで-39〜-70%劣化。R²=0.513の予測モデルが87%の精度で最適アーキテクチャを特定
- **improvement**: 並列可能タスクで最大+80.9%改善。逐次タスクでの-70%劣化を回避
- **severity**: critical

### SA-02: 中央集権型アーキテクチャの優先

- **check**: マルチエージェント構成において、独立型ではなく中央集権型（リードエージェント＋ワーカー）を採用しているか？
- **scope**: マルチエージェントの内部アーキテクチャ選択
- **action**: 独立型（各エージェントが自律的に動作）ではなく、中央集権型（オーケストレータが統括しワーカーに委任）を優先する
- **rationale**: 独立型マルチエージェントはエラーを17.2倍に増幅するのに対し、中央集権型は4.4倍に抑制（Google Research）
- **improvement**: エラー増幅を17.2倍→4.4倍に抑制
- **severity**: critical

### SA-03: エージェント当たりのツール数制限

- **check**: 1エージェントに割り当てるツール数が16未満に抑えられているか？
- **scope**: エージェントへのツール割り当て設計
- **action**: 1エージェントのツール数を16未満に制限する。多数のツールが必要な場合は、3階層アーキテクチャ（Level 1: ~20の安定コアツール、Level 2: CLI経由ユーティリティ、Level 3: 動的コード/パッケージ）や遅延読み込みを採用する
- **rationale**: ツール数16以上でツール間協調オーバーヘッドが急増しマルチエージェントの利点が消失（Google Research）。100以上でパラメータハルシネーション・誤ツール選択（Context Confusion）が発生（Manus AI）
- **improvement**: 実行時間最大70%短縮、消費電力40%削減、ツール選択精度の維持
- **severity**: major

### SA-04: コーディングタスクでの単一エージェント優先

- **check**: 共有状態を持つコーディングタスクにおいて、単一エージェント＋探索用サブエージェント（読み取り専用）の構成を基本としているか？
- **scope**: コードの読み書きを伴うタスクのアーキテクチャ設計
- **action**: 単一エージェントがコード編集を担当し、サブエージェントは探索・リサーチ（読み取り専用）のみを担当する構成にする。並列書き込みエージェントを使用しない
- **rationale**: 並列エージェントが互いに矛盾する暗黙的決定を行い不整合な出力を生成する（Cognition Labs）。サブエージェントがメインの完全なトレースを共有しないとミスコミュニケーションが蓄積する。Claude Codeの設計方針と一致
- **improvement**: 暗黙的決定の競合回避、出力の整合性維持
- **severity**: critical

### SA-05: テスト設計の独立エージェント化

- **check**: コード生成ワークフローにおいて、テスト設計をコード生成とは独立したエージェントに分離しているか？
- **scope**: テスト生成を含むコード生成ワークフロー
- **action**: テスト設計を専門の独立エージェントに分離し、コード生成エージェントとの反復フィードバックループ（生成→テスト→フィードバック→再生成）を構築する
- **rationale**: AgentCoderが3エージェント（Programmer+Test Designer+Test Executor）でHumanEval 96.3%（先行90.2%）、MBPP 91.8%（先行78.9%）を達成。テスト設計の分離により客観的かつ包括的なテストが生成される。MetaGPT（5エージェント）やChatDev（7エージェント）よりも少ないエージェント数で高性能
- **improvement**: pass@1で+6%以上。少エージェント+少トークン（56.9K vs 183.7K）で高性能
- **severity**: major

### SA-06: マルチエージェントのトークンコスト正当化

- **check**: マルチエージェント構成のトークンコスト増（約15倍）が、タスクの価値・改善幅で正当化できることを確認しているか？
- **scope**: マルチエージェント採用のコスト判断
- **action**: マルチエージェントは単一エージェントの約15倍のトークンを消費することを前提に、性能改善がコスト増を正当化する場合にのみ採用する。研究・情報収集タスクなど、トークン消費量自体が性能のドライバーとなるケースで特に有効
- **rationale**: Anthropicの測定でマルチエージェントはチャットの約15倍のトークンを消費。トークン使用量がBrowseComp性能分散の80%を説明し、ツール呼び出し回数とモデル選択が残り15%
- **improvement**: コスト最適化、不要なマルチエージェント化の回避。研究タスクでは+90.2%改善・研究時間最大90%短縮
- **severity**: major

---

## 3. コンテキスト・リソース管理

### CR-01: プロンプトプレフィックスの安定化

- **check**: プロンプトの先頭部分がリクエスト間で安定しており、タイムスタンプ等の変動要素が先頭に配置されていないか？
- **scope**: 複数リクエストを送信するワークフローのプロンプト設計
- **action**: プロンプトプレフィックスを安定化する。(1) 先頭にタイムスタンプを置かない、(2) append-only設計、(3) 決定的シリアライズ（sort_keys=True）、(4) ツール削除の代わりにロジットマスキング使用、(5) 手動キャッシュブレークポイント挿入
- **rationale**: エージェントの入出力トークン比100:1でプレフィックスキャッシュの影響が極大。キャッシュ済み$0.30/MTok vs 未キャッシュ$3.00/MTok（10倍差）。Manus AIがKVキャッシュヒット率を「プロダクションエージェントの最重要メトリクス」と定義
- **improvement**: レイテンシ64%改善、コスト71.3%削減（年間約$237,500削減@10K req/day）
- **severity**: critical

### CR-02: コンテキストのappend-only設計

- **check**: コンテキストの更新が既存プレフィックスを変更せず、末尾への追加のみで行われているか？
- **scope**: エージェントのコンテキスト管理・更新設計
- **action**: コンテキストは既存部分を変更せず末尾への追加のみで更新するappend-only設計を採用する。中間部分の変更が必要な場合は、変更を末尾に差分として追加する
- **rationale**: 中間部分の変更はKVキャッシュを無効化し全トークンの再計算が必要。Anthropicの明示的キャッシュは100%ヒット率を達成する一方、中間変更で全て無効化される
- **improvement**: APIコスト45-80%削減、TTFT 13-31%改善。キャッシュ書き込みは25%上乗せのため2回のAPIコールで損益分岐
- **severity**: critical

### CR-03: 観測マスキングの優先採用

- **check**: コンテキスト圧縮において、全面要約ではなく、古いターンの観測部分のみをマスクし推論・行動履歴を保持する方式を優先しているか？
- **scope**: コンテキスト圧縮戦略の選択
- **action**: 古いターンの観測部分（テストログ、ファイル読取結果等）のみをマスクし、推論トレースと行動の履歴は完全に保持する。マスキングと選択的要約のハイブリッドが最良のコスト・性能トレードオフを達成
- **rationale**: エージェントの観測がトークン消費の最大源。全面要約は詳細喪失のリスクがある。観測マスキングは効率的にサイズを削減しつつ推論品質を維持（JetBrains Research, NeurIPS 2025）
- **improvement**: 22.7%平均トークン削減（最良ケースで57%削減）、精度維持
- **severity**: major

### CR-04: 段階的コンテキスト圧縮閾値

- **check**: コンテキストウィンドウ管理に段階的な圧縮閾値（早期警告→危機的→緊急）を設定しているか？
- **scope**: 長時間稼働するエージェントのコンテキストウィンドウ管理
- **action**: 3段階の閾値を設定する。早期警告（容量40%）：非アクティブファイルを構造的サマリに。危機的（60%）：古い会話ターンをLLM要約に。緊急（95%）：最初2ターン+最後3ターンのみ原文保持。1Mコンテキストモデルでは約256K（25%）付近から性能劣化が始まるため、その前に圧縮を開始する
- **rationale**: トークン間のn²ペアワイズ関係により、コンテキスト増大に伴い注意が薄く引き伸ばされる。Manus AIの「Pre-Rot Threshold」概念。LoCoBench-Agentの3段階システム
- **improvement**: コンテキスト寿命の最大化、性能劣化タイミングの遅延
- **severity**: major

### CR-05: 直近ターンの原文保持

- **check**: コンテキスト圧縮時に、最後の3ターンを常に非圧縮の原文形式で保持しているか？
- **scope**: コンテキスト圧縮の実装
- **action**: 圧縮の優先順位を「生コンテキスト削減 > 観測マスキング > 要約」とし、最後の3ターンは常に原文形式で保持する
- **rationale**: 直近のコンテキストが出力品質に最も影響する。圧縮すると出力品質が劣化する（Manus AI, LoCoBench-Agent）
- **improvement**: 圧縮適用時の出力品質劣化の防止
- **severity**: major

### CR-06: ツール提供数の最小化

- **check**: エージェントに同時提供するツールの数が必要最小限に抑えられているか？
- **scope**: エージェントのツール設計・配置
- **action**: 同時提供ツール数を最小限にする。大量のツールが必要な場合は3階層アーキテクチャ（Level 1: ~20コアツール、Level 2: CLI経由ユーティリティ、Level 3: 動的コード/パッケージ）や遅延読み込み（MCPツール定義がコンテキストの10%超で自動発動）を採用する
- **rationale**: 100以上のツール同時提供でパラメータハルシネーション・誤選択（Context Confusion）が発生（Manus AI）。ツール数削減で実行時間最大70%短縮・消費電力40%削減（arXiv:2411.15399）
- **improvement**: 実行時間最大70%短縮、ハルシネーション回避
- **severity**: major

### CR-07: ASTベースのコードチャンキング

- **check**: コードベースのインデキシング・検索において、行ベース分割ではなくAST（抽象構文木）ベースのチャンキングを使用しているか？
- **scope**: コードベースRAG・検索システムの設計
- **action**: ナイーブな行ベース分割ではなく、ASTベースのチャンキングを採用する。可能であれば埋め込み検索・grep・知識グラフ・AST解析を組み合わせた複合アプローチを検討する。コードの自然言語サマリ生成も検索精度を向上させる
- **rationale**: cAST（arXiv:2506.15655）でRecall@5が+4.3pt、Pass@1が+2.67pt。ノードベースコンテキストはチャンクベースの約2倍のPass@1（16.67% vs 8.46%）。Meta-RAGの自然言語サマリでコードベースサイズ80%削減かつ精度84.67%（BM25の1.4倍）。Windsurfの複合手法で単一手法比3倍の検索精度
- **improvement**: 検索Recall@5 +4.3pt、Pass@1 約2倍、複合手法で3倍の検索精度
- **severity**: major
